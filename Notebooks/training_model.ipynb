{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ed7779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Standard Library --------------------\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------- Core Scientific Libraries --------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------- Visualization --------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------- Scikit-learn Core --------------------\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "\n",
    "# -------------------- Gradient Boosting --------------------\n",
    "import xgboost as xgb\n",
    "\n",
    "# -------------------- Imbalanced Learning --------------------\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# -------------------- Experiment Tracking (MLflow) --------------------\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# -------------------- Model Persistence --------------------\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef6fc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend  label  \n",
       "0     shopping        0.0      0  \n",
       "1  electronics        0.0      0  \n",
       "2         food        1.0      0  \n",
       "3  electronics        1.0      0  \n",
       "4     shopping        0.0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Asus\\Downloads\\Fraud_MLOps_Project\\Data\\payment_fraud.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "296d4d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [accountAgeDays, numItems, localTime, paymentMethod, paymentMethodAgeDays, Category, isWeekend, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df.drop(columns=['label']).notna().all(axis=1) & (df['label'] == 1)]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14257b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlruns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb0241",
   "metadata": {},
   "source": [
    "# Model Sub Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom feature engineering transformer.\n",
    "    Controlled via steps_to_apply list:\n",
    "    - 'feature_engineering': enable feature engineering\n",
    "    - 'interaction': Category x PaymentMethod\n",
    "    - 'ratio': paymentMethodAgeDays / accountAgeDays\n",
    "    - 'binning': bins for accountAgeDays\n",
    "    - 'time_feature': bins for localTime\n",
    "    \"\"\"\n",
    "    def __init__(self, steps_to_apply=None):\n",
    "        self.steps_to_apply = steps_to_apply or []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        # Skip entire feature engineering if 'feature_engineering' not in steps\n",
    "        if 'feature_engineering' not in self.steps_to_apply:\n",
    "            return X\n",
    "\n",
    "        # Interaction Feature\n",
    "        if 'interaction' in self.steps_to_apply:\n",
    "            if 'Category' in X.columns and 'paymentMethod' in X.columns:\n",
    "                X['Category_Payment'] = X['Category'] + '_' + X['paymentMethod']\n",
    "\n",
    "        # Ratio Feature\n",
    "        if 'ratio' in self.steps_to_apply:\n",
    "            if 'paymentMethodAgeDays' in X.columns and 'accountAgeDays' in X.columns:\n",
    "                X['payment_account_ratio'] = X['paymentMethodAgeDays'] / (X['accountAgeDays'] + 1)\n",
    "\n",
    "        # Binning Feature\n",
    "        if 'binning' in self.steps_to_apply:\n",
    "            if 'accountAgeDays' in X.columns:\n",
    "                X['account_age_bin'] = pd.cut(\n",
    "                    X['accountAgeDays'],\n",
    "                    bins=[0, 90, 730, 2000],\n",
    "                    labels=['new', 'medium', 'old']\n",
    "                )\n",
    "\n",
    "        # Time-of-day Feature\n",
    "        if 'time_feature' in self.steps_to_apply:\n",
    "            if 'localTime' in X.columns:\n",
    "                bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]\n",
    "                labels = ['early_morning', 'morning', 'afternoon', 'evening', 'night']\n",
    "                X['time_of_day'] = pd.cut(X['localTime'], bins=bins, labels=labels)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecf46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Log Transformer -----------\n",
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.log1p(np.array(X, dtype=float))\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return input_features\n",
    "\n",
    "\n",
    "# ----------- Preprocessing Class -----------\n",
    "class Preprocessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features, skewed_features, symmetric_features,\n",
    "                 steps_to_apply=None, random_state=42):\n",
    "        \"\"\"\n",
    "        Preprocessing pipeline (impute, encoding, log, scaling).\n",
    "        SMOTE/ADASYN will be applied separately after this step.\n",
    "        \"\"\"\n",
    "        self.categorical_features = categorical_features\n",
    "        self.skewed_features = skewed_features\n",
    "        self.symmetric_features = symmetric_features\n",
    "        self.steps_to_apply = steps_to_apply or []\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self.preprocessor = None  # ColumnTransformer will be built dynamically\n",
    "\n",
    "    def _build_pipeline(self):\n",
    "        \"\"\"Build column transformer dynamically based on steps_to_apply.\"\"\"\n",
    "\n",
    "        # ----- Categorical pipeline -----\n",
    "        cat_steps = []\n",
    "        if 'impute' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            cat_steps.append(('imputer', SimpleImputer(strategy='most_frequent')))\n",
    "        if 'encoding' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            cat_steps.append(('encoder', OneHotEncoder(handle_unknown='ignore', drop='first')))\n",
    "        cat_pipeline = Pipeline(cat_steps) if cat_steps else 'passthrough'\n",
    "\n",
    "        # ----- Skewed numerical pipeline -----\n",
    "        skewed_steps = []\n",
    "        if 'impute' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            skewed_steps.append(('imputer', SimpleImputer(strategy='median')))\n",
    "        if 'log_transform' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            skewed_steps.append(('log', LogTransformer()))\n",
    "        if 'encoding' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:  # scaling numeric\n",
    "            skewed_steps.append(('scaler', StandardScaler()))\n",
    "        skewed_pipeline = Pipeline(skewed_steps) if skewed_steps else 'passthrough'\n",
    "\n",
    "        # ----- Symmetric numerical pipeline -----\n",
    "        sym_steps = []\n",
    "        if 'impute' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            sym_steps.append(('imputer', SimpleImputer(strategy='median')))\n",
    "        if 'encoding' in self.steps_to_apply or 'preprocessing' in self.steps_to_apply:\n",
    "            sym_steps.append(('scaler', MinMaxScaler()))\n",
    "        sym_pipeline = Pipeline(sym_steps) if sym_steps else 'passthrough'\n",
    "\n",
    "        # ----- Combine all pipelines -----\n",
    "        self.preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', cat_pipeline, self.categorical_features),\n",
    "                ('skew', skewed_pipeline, self.skewed_features),\n",
    "                ('sym', sym_pipeline, self.symmetric_features)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._build_pipeline()\n",
    "        self.preprocessor.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform WITHOUT resampling (pure preprocessing).\"\"\"\n",
    "        return self.preprocessor.transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform WITHOUT resampling (SMOTE will be handled outside).\"\"\"\n",
    "        self._build_pipeline()\n",
    "        return self.preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d588eb",
   "metadata": {},
   "source": [
    "# Integrated Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dd86066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Downloads\\Fraud_MLOps_Project\\.venv\\Lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- FRAUD PIPELINE CLASS -------------------------\n",
    "class FraudPipeline(mlflow.pyfunc.PythonModel):\n",
    "    # ----- Step mappings -----\n",
    "    FEATURE_ENG_SUBSTEPS = ['interaction', 'ratio', 'binning', 'time_feature']\n",
    "    PREPROCESS_SUBSTEPS = ['encoding', 'impute', 'log_transform', 'smote']\n",
    "    \n",
    "    def __init__(self, steps_to_apply=None, model=None, test_size=0.2,\n",
    "                 random_state=42, resample_method=\"smote\", experiment_name=\"FraudDetection\"):\n",
    "        self.steps_to_apply = self.expand_steps(steps_to_apply)\n",
    "        self.model = model or RandomForestClassifier(class_weight='balanced', random_state=random_state)\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.resample_method = resample_method\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        # Pipeline placeholder\n",
    "        self.pipeline = None\n",
    "        self.best_threshold = 0.5  # Default threshold (updated after training)\n",
    "\n",
    "        # Feature groups\n",
    "        self.categorical = ['Category', 'paymentMethod', 'isWeekend']\n",
    "        self.skewed = ['numItems', 'localTime', 'paymentMethodAgeDays']\n",
    "        self.symmetric = ['accountAgeDays']\n",
    "        self.target = 'label'\n",
    "\n",
    "        # Initialize MLflow experiment\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "    # ------------------------- STEP EXPANSION -------------------------\n",
    "    def expand_steps(self, steps_to_apply):\n",
    "        \"\"\"Strict parent-substep logic with full-step auto expansion.\"\"\"\n",
    "        steps = set(steps_to_apply or [])\n",
    "\n",
    "        # ---------- Feature Engineering ----------\n",
    "        fe_substeps = steps.intersection(self.FEATURE_ENG_SUBSTEPS)\n",
    "\n",
    "        if fe_substeps and 'feature_engineering' not in steps:\n",
    "            raise ValueError(\n",
    "                f\"Feature engineering sub-steps {fe_substeps} provided without 'feature_engineering' parent step.\"\n",
    "            )\n",
    "\n",
    "        if 'feature_engineering' in steps:\n",
    "            if fe_substeps:\n",
    "                steps = steps  # Only chosen sub-steps\n",
    "            else:\n",
    "                steps.update(self.FEATURE_ENG_SUBSTEPS)  # Apply all sub-steps\n",
    "\n",
    "        # ---------- Preprocessing ----------\n",
    "        pre_substeps = steps.intersection(self.PREPROCESS_SUBSTEPS)\n",
    "\n",
    "        if pre_substeps and 'preprocessing' not in steps:\n",
    "            raise ValueError(\n",
    "                f\"Preprocessing sub-steps {pre_substeps} provided without 'preprocessing' parent step.\"\n",
    "            )\n",
    "\n",
    "        if 'preprocessing' in steps:\n",
    "            if pre_substeps:\n",
    "                steps = steps\n",
    "            else:\n",
    "                steps.update(self.PREPROCESS_SUBSTEPS)  # Apply all preprocessing steps\n",
    "\n",
    "        return list(steps)\n",
    "\n",
    "    # ------------------------- TRAIN -------------------------\n",
    "    def train(self, df):\n",
    "        \"\"\"Fit full pipeline with no data leakage and log experiment metadata.\"\"\"\n",
    "\n",
    "        # --- Split ---\n",
    "        X = df.drop(columns=[self.target])\n",
    "        y = df[self.target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, stratify=y, test_size=self.test_size, random_state=self.random_state, shuffle=True\n",
    "        )\n",
    "\n",
    "        # --- Feature Engineering Step ---\n",
    "        feature_engineer = FeatureEngineering(steps_to_apply=self.steps_to_apply) \\\n",
    "            if any(s in self.steps_to_apply for s in self.FEATURE_ENG_SUBSTEPS) else 'passthrough'\n",
    "\n",
    "        # --- Preprocessing Step ---\n",
    "        preprocessor = Preprocessing(\n",
    "            self.categorical, self.skewed, self.symmetric,\n",
    "            steps_to_apply=self.steps_to_apply,\n",
    "            random_state=self.random_state\n",
    "        ) if any(s in self.steps_to_apply for s in self.PREPROCESS_SUBSTEPS) else 'passthrough'\n",
    "\n",
    "        # --- Build pipeline (no resampling in pipeline) ---\n",
    "        self.pipeline = ImbPipeline([\n",
    "            ('feature_engineering', feature_engineer),\n",
    "            ('preprocessing', preprocessor),\n",
    "            ('model', self.model)\n",
    "        ])\n",
    "\n",
    "        # --- Transform Train/Test separately (no leakage) ---\n",
    "        X_train_transformed = self.pipeline[:-1].fit_transform(X_train, y_train)\n",
    "        X_test_transformed = self.pipeline[:-1].transform(X_test)\n",
    "\n",
    "        # --- Apply SMOTE/ADASYN only on Train ---\n",
    "        if 'smote' in self.steps_to_apply:\n",
    "            if self.resample_method == \"smote\":\n",
    "                sampler = SMOTE(random_state=self.random_state, sampling_strategy='minority', k_neighbors=5)\n",
    "            elif self.resample_method == \"adasyn\":\n",
    "                sampler = ADASYN(random_state=self.random_state, sampling_strategy='minority', n_neighbors=5)\n",
    "            else:\n",
    "                raise ValueError(\"resample_method must be 'smote' or 'adasyn'\")\n",
    "\n",
    "            X_train_transformed, y_train = sampler.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "        # --- Train Model ---\n",
    "        if 'model_training' in self.steps_to_apply:\n",
    "            with mlflow.start_run(run_name=f\"{type(self.model).__name__}_run\"):\n",
    "                # -------- Log Parameters --------\n",
    "                mlflow.log_param(\"steps_to_apply\", self.steps_to_apply)\n",
    "                mlflow.log_param(\"resample_method\", self.resample_method)\n",
    "                mlflow.log_param(\"test_size\", self.test_size)\n",
    "                mlflow.log_param(\"model\", type(self.model).__name__)\n",
    "                mlflow.log_param(\"categorical_features\", self.categorical)\n",
    "                mlflow.log_param(\"skewed_features\", self.skewed)\n",
    "                mlflow.log_param(\"symmetric_features\", self.symmetric)\n",
    "\n",
    "                # -------- Train and Evaluate --------\n",
    "                self.model.fit(X_train_transformed, y_train)\n",
    "\n",
    "                # Threshold tuning using TRAIN probabilities\n",
    "                y_train_proba = self.model.predict_proba(X_train_transformed)[:, 1]\n",
    "                precision, recall, thresholds = precision_recall_curve(y_train, y_train_proba)\n",
    "                f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "                best_idx = f1_scores.argmax()\n",
    "                self.best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "                mlflow.log_param(\"optimal_threshold\", self.best_threshold)\n",
    "\n",
    "                print(f\"Optimal Threshold (from train): {self.best_threshold:.3f} \"\n",
    "                      f\"(Precision={precision[best_idx]:.3f}, Recall={recall[best_idx]:.3f})\")\n",
    "\n",
    "                # Evaluate train/test metrics (default 0.5 threshold)\n",
    "                y_train_pred = self.model.predict(X_train_transformed)\n",
    "                y_test_pred = self.model.predict(X_test_transformed)\n",
    "\n",
    "                train_metrics = self._calculate_metrics(y_train, y_train_pred, prefix=\"train\")\n",
    "                test_metrics = self._calculate_metrics(y_test, y_test_pred, prefix=\"test\")\n",
    "                self._log_metrics(train_metrics)\n",
    "                self._log_metrics(test_metrics)\n",
    "\n",
    "                # Log PR-AUC on TEST set\n",
    "                y_test_proba = self.model.predict_proba(X_test_transformed)[:, 1]\n",
    "                pr_auc = average_precision_score(y_test, y_test_proba)\n",
    "                mlflow.log_metric(\"test_pr_auc\", pr_auc)\n",
    "\n",
    "                # --- Save PR curve ---\n",
    "                precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                plt.plot(recall_test, precision_test, label=f'PR curve (AUC={pr_auc:.3f})')\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                plt.title('Precision-Recall Curve (Test)')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                pr_curve_path = \"artifacts/pr_curve.png\"\n",
    "                os.makedirs(\"artifacts\", exist_ok=True)\n",
    "                plt.savefig(pr_curve_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(pr_curve_path, \"precision_recall_curve\")\n",
    "\n",
    "                # --- Confusion matrix ---\n",
    "                cm = confusion_matrix(y_test, y_test_pred)\n",
    "                fig, ax = plt.subplots(figsize=(6, 4))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "                ax.set_title('Confusion Matrix')\n",
    "                ax.set_xlabel('Predicted')\n",
    "                ax.set_ylabel('Actual')\n",
    "                cm_png_path = \"artifacts/confusion_matrix.png\"\n",
    "                plt.savefig(cm_png_path, bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "                mlflow.log_artifact(cm_png_path, \"confusion_matrix\")\n",
    "\n",
    "                # --- Log data distribution ---\n",
    "                class_dist = y.value_counts(normalize=True).to_dict()\n",
    "                mlflow.log_param(\"class_distribution\", json.dumps(class_dist))\n",
    "\n",
    "                # --- Log model to MLflow ---\n",
    "                signature = infer_signature(X_train, self.model.predict(X_train_transformed))\n",
    "                # mlflow.sklearn.log_model(self, name=\"fraud_pipeline\", signature=signature)\n",
    "                mlflow.pyfunc.log_model(name=\"fraud_pipeline\", python_model=self, signature=signature)\n",
    "\n",
    "                # Save pipeline locally\n",
    "                # joblib.dump(self.pipeline, \"artifacts/fraud_pipeline.pkl\")\n",
    "                joblib.dump(self, \"artifacts/fraud_pipeline.pkl\")\n",
    "                mlflow.log_artifacts(\"artifacts\")\n",
    "\n",
    "        return self.pipeline, X_train_transformed, y_train, X_test_transformed, y_test\n",
    "\n",
    "    # ------------------------- PREPROCESS -------------------------\n",
    "    def preprocess(self, df):\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"Pipeline not trained. Train first or load fitted pipeline.\")\n",
    "        return self.pipeline[:-1].transform(df)\n",
    "\n",
    "    # ------------------------- PREDICT -------------------------\n",
    "    def predict_pipeline(self, df, use_optimal_threshold=False):\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"Pipeline not trained. Train first or load fitted pipeline.\")\n",
    "        \n",
    "        # Transform if DataFrame\n",
    "        transformed = self.pipeline[:-1].transform(df) if isinstance(df, pd.DataFrame) else df\n",
    "\n",
    "        if use_optimal_threshold:\n",
    "            probs = self.pipeline[-1].predict_proba(transformed)[:, 1]\n",
    "            return (probs >= self.best_threshold).astype(int)\n",
    "        else:\n",
    "            return self.pipeline[-1].predict(transformed)\n",
    "    \n",
    "    # ------------------------- MLflow Required PREDICT -------------------------\n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        This method is called during MLflow serving (Docker).\n",
    "        It always uses the best threshold for predictions.\n",
    "        \"\"\"\n",
    "        return self.predict_pipeline(model_input, use_optimal_threshold=True)\n",
    "\n",
    "    # ------------------------- PREDICT PROBA -------------------------\n",
    "    def predict_proba(self, df):\n",
    "        \"\"\"Return fraud probability predictions (class 1).\"\"\"\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"Pipeline not trained. Train first or load fitted pipeline.\")\n",
    "        \n",
    "        transformed = self.pipeline[:-1].transform(df) if isinstance(df, pd.DataFrame) else df\n",
    "        return self.pipeline[-1].predict_proba(transformed)[:, 1]\n",
    "\n",
    "    # ------------------------- METRICS UTILS -------------------------\n",
    "    def _calculate_metrics(self, y_true, y_pred, prefix=\"\"):\n",
    "        return {\n",
    "            f\"{prefix}_accuracy\": accuracy_score(y_true, y_pred),\n",
    "            f\"{prefix}_precision\": precision_score(y_true, y_pred),\n",
    "            f\"{prefix}_recall\": recall_score(y_true, y_pred),\n",
    "            f\"{prefix}_f1\": f1_score(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "    def _log_metrics(self, metrics):\n",
    "        for k, v in metrics.items():\n",
    "            mlflow.log_metric(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905cfb0",
   "metadata": {},
   "source": [
    "# Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal data size: (39221, 8)\n",
      "Cleaned (without duplicates) data size: (36188, 8)\n",
      "Training data size: (35788, 8)\n",
      "Hold-out data A size: (100, 8)\n",
      "Hold-out data B size: (100, 8)\n",
      "Hold-out data C size: (100, 8)\n",
      "Optimal Threshold (from train): 0.800 (Precision=0.955, Recall=0.991)\n",
      "Best Threshold:  0.8000408088064991\n",
      "\n",
      "--- Internal Test Split Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      7099\n",
      "           1       0.14      0.95      0.24        59\n",
      "\n",
      "    accuracy                           0.95      7158\n",
      "   macro avg       0.57      0.95      0.61      7158\n",
      "weighted avg       0.99      0.95      0.97      7158\n",
      "\n",
      "Internal Test Split Accuracy:  0.9500\n",
      "Internal Test Split Precision: 0.1363\n",
      "Internal Test Split Recall:    0.9492\n",
      "Internal Test Split F1 Score:   0.2383\n",
      "\n",
      "--- Hold-out Set A Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        99\n",
      "           1       0.20      1.00      0.33         1\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.60      0.98      0.66       100\n",
      "weighted avg       0.99      0.96      0.97       100\n",
      "\n",
      "Hold-out Set A Accuracy:  0.9600\n",
      "Hold-out Set A Precision: 0.2000\n",
      "Hold-out Set A Recall:    1.0000\n",
      "Hold-out Set A F1 Score:   0.3333\n",
      "\n",
      "--- Hold-out Set B Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        99\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.62      0.98      0.69       100\n",
      "weighted avg       0.99      0.97      0.98       100\n",
      "\n",
      "Hold-out Set B Accuracy:  0.9700\n",
      "Hold-out Set B Precision: 0.2500\n",
      "Hold-out Set B Recall:    1.0000\n",
      "Hold-out Set B F1 Score:   0.4000\n",
      "\n",
      "--- Hold-out Set C Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.96      0.98      0.97       100\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.97      0.97      0.97       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n",
      "Hold-out Set C Accuracy:  0.9700\n",
      "Hold-out Set C Precision: 0.9608\n",
      "Hold-out Set C Recall:    0.9800\n",
      "Hold-out Set C F1 Score:   0.9703\n",
      "\n",
      "Pipeline saved as 'fraud_pipeline_deployed.pkl'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18192</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24727</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25217</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predictions  True_Value\n",
       "35999            0           0\n",
       "18192            1           0\n",
       "5589             0           0\n",
       "18168            0           0\n",
       "24727            0           0\n",
       "...            ...         ...\n",
       "25217            1           0\n",
       "8568             0           0\n",
       "7560             0           0\n",
       "28968            0           0\n",
       "5727             1           1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35825</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19651</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9782</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13045</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predictions  True_Value\n",
       "6153             0           0\n",
       "660              0           0\n",
       "26114            0           0\n",
       "35825            0           0\n",
       "13314            0           0\n",
       "...            ...         ...\n",
       "19651            0           0\n",
       "13654            0           0\n",
       "9782             0           0\n",
       "13045            0           0\n",
       "6037             1           1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>True_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32649</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20942</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15793</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33401</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predictions  True_Value\n",
       "36787            0           0\n",
       "17068            0           0\n",
       "32649            0           0\n",
       "34687            0           0\n",
       "20942            0           0\n",
       "...            ...         ...\n",
       "15793            0           0\n",
       "33401            0           0\n",
       "32322            0           0\n",
       "37823            0           0\n",
       "24437            0           0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, dataset_name=\"Evaluation\", is_proba=False):\n",
    "    \"\"\"\n",
    "    Prints and returns classification metrics with optional PR-AUC and threshold tuning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        True labels.\n",
    "    y_pred : array-like\n",
    "        Predicted labels or probabilities.\n",
    "    dataset_name : str\n",
    "        Name for the dataset (used in print titles and keys).\n",
    "    is_proba : bool\n",
    "        If True, `y_pred` is treated as probabilities for PR-AUC and threshold tuning.\n",
    "    \"\"\"\n",
    "    best_threshold = 0.5  # Default threshold\n",
    "\n",
    "    if is_proba:\n",
    "        # --- Compute PR-AUC ---\n",
    "        pr_auc = average_precision_score(y_true, y_pred)\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "\n",
    "        # --- Find best threshold (maximize F1) ---\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        best_idx = f1_scores.argmax()\n",
    "        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
    "\n",
    "        print(f\"\\n--- {dataset_name} PR-AUC: {pr_auc:.4f} ---\")\n",
    "        print(f\"Optimal Threshold: {best_threshold:.3f} \"\n",
    "              f\"(Precision={precision[best_idx]:.3f}, Recall={recall[best_idx]:.3f})\")\n",
    "\n",
    "        # Convert probabilities to binary using best threshold\n",
    "        y_pred = (y_pred >= best_threshold).astype(int)\n",
    "\n",
    "    # --- Classification report ---\n",
    "    print(f\"\\n--- {dataset_name} Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # --- Compute summary metrics ---\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_val = precision_score(y_true, y_pred)\n",
    "    recall_val = recall_score(y_true, y_pred)\n",
    "    f1_val = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{dataset_name} Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"{dataset_name} Precision: {precision_val:.4f}\")\n",
    "    print(f\"{dataset_name} Recall:    {recall_val:.4f}\")\n",
    "    print(f\"{dataset_name} F1 Score:   {f1_val:.4f}\")\n",
    "\n",
    "    # --- Return results ---\n",
    "    result = {\n",
    "        f\"{dataset_name}_accuracy\": accuracy,\n",
    "        f\"{dataset_name}_precision\": precision_val,\n",
    "        f\"{dataset_name}_recall\": recall_val,\n",
    "        f\"{dataset_name}_f1\": f1_val,\n",
    "    }\n",
    "    if is_proba:\n",
    "        result[f\"{dataset_name}_pr_auc\"] = pr_auc\n",
    "        result[f\"{dataset_name}_best_threshold\"] = best_threshold\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ----------------------- Step 1: Create Hold-out Set -----------------------\n",
    "df_clean = df.drop_duplicates(keep='first')\n",
    "\n",
    "n1, n2 = 99, 1\n",
    "n = 50\n",
    "\n",
    "holdout_class_0_A = df_clean[df_clean['label'] == 0].sample(n1, random_state=42)\n",
    "holdout_class_1_A = df_clean[df_clean['label'] == 1].sample(n2, random_state=42)\n",
    "holdout_df_A = pd.concat([holdout_class_0_A, holdout_class_1_A])\n",
    "\n",
    "train_df = df_clean.drop(holdout_df_A.index)\n",
    "\n",
    "X_holdout_A = holdout_df_A.drop(columns=['label'])\n",
    "y_holdout_A = holdout_df_A['label']\n",
    "\n",
    "holdout_class_0_B = train_df[train_df['label'] == 0].sample(n1, random_state=42)\n",
    "holdout_class_1_B = train_df[train_df['label'] == 1].sample(n2, random_state=42)\n",
    "holdout_df_B = pd.concat([holdout_class_0_B, holdout_class_1_B])\n",
    "\n",
    "train_df = train_df.drop(holdout_df_B.index)\n",
    "\n",
    "X_holdout_B = holdout_df_B.drop(columns=['label'])\n",
    "y_holdout_B = holdout_df_B['label']\n",
    "\n",
    "holdout_class_0_C = train_df[train_df['label'] == 0].sample(n, random_state=42)\n",
    "holdout_class_1_C = train_df[train_df['label'] == 1].sample(n, random_state=42)\n",
    "holdout_df_C = pd.concat([holdout_class_0_C, holdout_class_1_C])\n",
    "\n",
    "train_df = train_df.drop(holdout_df_C.index)\n",
    "\n",
    "X_holdout_C = holdout_df_C.drop(columns=['label'])\n",
    "y_holdout_C = holdout_df_C['label']\n",
    "\n",
    "print(f'Orignal data size: {df.shape}')\n",
    "print(f'Cleaned (without duplicates) data size: {df_clean.shape}')\n",
    "print(f\"Training data size: {train_df.shape}\")\n",
    "print(f\"Hold-out data A size: {holdout_df_A.shape}\")\n",
    "print(f\"Hold-out data B size: {holdout_df_B.shape}\")\n",
    "print(f\"Hold-out data C size: {holdout_df_B.shape}\")\n",
    "\n",
    "# ----------------------- Step 2: Initialize FraudPipeline -----------------------\n",
    "fp = FraudPipeline(\n",
    "    steps_to_apply=[\n",
    "        'feature_engineering', \n",
    "        # 'interaction', \n",
    "        # 'ratio', \n",
    "        # 'binning', \n",
    "        # 'time_feature',\n",
    "        \n",
    "        'preprocessing', \n",
    "        # 'encoding', \n",
    "        # 'impute', \n",
    "        # 'log_transform', \n",
    "        # 'smote', \n",
    "        \n",
    "        'model_training',\n",
    "    ],\n",
    "    resample_method='smote',\n",
    "    # model=xgb.XGBClassifier(),\n",
    "    model=LogisticRegression(),\n",
    ")\n",
    "\n",
    "# ----------------------- Step 3: Train Pipeline -----------------------\n",
    "pipeline, X_train, y_train, X_test, y_test = fp.train(train_df)\n",
    "print('Best Threshold: ', fp.best_threshold)\n",
    "# ----------------------- Step 4: Evaluate on Internal Test Split -----------------------\n",
    "# Get probabilities and apply stored threshold\n",
    "test_probabilities = fp.predict_proba(X_test)\n",
    "test_preds = (test_probabilities >= fp.best_threshold).astype(int)\n",
    "test_metrics = evaluate_model(y_test, test_preds, dataset_name=\"Internal Test Split\")\n",
    "\n",
    "# ----------------------- Step 5: Evaluate on Hold-out Sets -----------------------\n",
    "# Hold-out Set A\n",
    "holdout_prob_A = fp.predict_proba(X_holdout_A)\n",
    "holdout_preds_A = (holdout_prob_A >= fp.best_threshold).astype(int)\n",
    "holdout_metrics_A = evaluate_model(y_holdout_A, holdout_preds_A, dataset_name=\"Hold-out Set A\")\n",
    "\n",
    "# Hold-out Set B\n",
    "holdout_prob_B = fp.predict_proba(X_holdout_B)\n",
    "holdout_preds_B = (holdout_prob_B >= fp.best_threshold).astype(int)\n",
    "holdout_metrics_B = evaluate_model(y_holdout_B, holdout_preds_B, dataset_name=\"Hold-out Set B\")\n",
    "\n",
    "# Hold-out Set C\n",
    "holdout_prob_C = fp.predict_proba(X_holdout_C)\n",
    "holdout_preds_C = (holdout_prob_C >= fp.best_threshold).astype(int)\n",
    "holdout_metrics_C = evaluate_model(y_holdout_C, holdout_preds_C, dataset_name=\"Hold-out Set C\")\n",
    "\n",
    "# ----------------------- Step 6: Save Pipeline -----------------------\n",
    "joblib.dump(fp.pipeline, \"fraud_pipeline_deployed.pkl\")\n",
    "print(\"\\nPipeline saved as 'fraud_pipeline_deployed.pkl'\")\n",
    "\n",
    "# ----------------------- Step 7: Load & Predict (Example) -----------------------\n",
    "loaded_pipeline = joblib.load(\"fraud_pipeline_deployed.pkl\")\n",
    "sample_preds_A = loaded_pipeline.predict(X_holdout_A)\n",
    "sample_preds_B = loaded_pipeline.predict(X_holdout_B)\n",
    "sample_preds_C = loaded_pipeline.predict(X_holdout_C)\n",
    "\n",
    "display(pd.DataFrame({'Predictions': sample_preds_A, 'True_Value': y_holdout_A}).head(100))\n",
    "display(pd.DataFrame({'Predictions': sample_preds_B, 'True_Value': y_holdout_B}).head(100))\n",
    "display(pd.DataFrame({'Predictions': sample_preds_C, 'True_Value': y_holdout_C}).head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLD OUT A DATA\n",
      "True_Value\n",
      "0    99\n",
      "1     1\n",
      "Name: count, dtype: int64\n",
      "Predictions\n",
      "0    89\n",
      "1    11\n",
      "Name: count, dtype: int64\n",
      "HOLD OUT B DATA\n",
      "True_Value\n",
      "0    99\n",
      "1     1\n",
      "Name: count, dtype: int64\n",
      "Predictions\n",
      "0    94\n",
      "1     6\n",
      "Name: count, dtype: int64\n",
      "HOLD OUT C DATA\n",
      "True_Value\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "Predictions\n",
      "1    51\n",
      "0    49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('HOLD OUT A DATA')\n",
    "print(pd.DataFrame({'Predictions': sample_preds_A, 'True_Value': y_holdout_A})['True_Value'].value_counts())\n",
    "print(pd.DataFrame({'Predictions': sample_preds_A, 'True_Value': y_holdout_A})['Predictions'].value_counts())\n",
    "print('HOLD OUT B DATA')\n",
    "print(pd.DataFrame({'Predictions': sample_preds_B, 'True_Value': y_holdout_B})['True_Value'].value_counts())\n",
    "print(pd.DataFrame({'Predictions': sample_preds_B, 'True_Value': y_holdout_B})['Predictions'].value_counts())\n",
    "print('HOLD OUT C DATA')\n",
    "print(pd.DataFrame({'Predictions': sample_preds_C, 'True_Value': y_holdout_C})['True_Value'].value_counts())\n",
    "print(pd.DataFrame({'Predictions': sample_preds_C, 'True_Value': y_holdout_C})['Predictions'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3d039",
   "metadata": {},
   "source": [
    "# Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c366d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hold-out A Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        99\n",
      "           1       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.62      0.98      0.69       100\n",
      "weighted avg       0.99      0.97      0.98       100\n",
      "\n",
      "Hold-out A Accuracy:  0.9700\n",
      "Hold-out A Precision: 0.2500\n",
      "Hold-out A Recall:    1.0000\n",
      "Hold-out A F1 Score:   0.4000\n",
      "\n",
      "--- Hold-out B Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        99\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.99       100\n",
      "   macro avg       0.75      0.99      0.83       100\n",
      "weighted avg       0.99      0.99      0.99       100\n",
      "\n",
      "Hold-out B Accuracy:  0.9900\n",
      "Hold-out B Precision: 0.5000\n",
      "Hold-out B Recall:    1.0000\n",
      "Hold-out B F1 Score:   0.6667\n",
      "\n",
      "--- Hold-out C Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        50\n",
      "           1       0.98      0.98      0.98        50\n",
      "\n",
      "    accuracy                           0.98       100\n",
      "   macro avg       0.98      0.98      0.98       100\n",
      "weighted avg       0.98      0.98      0.98       100\n",
      "\n",
      "Hold-out C Accuracy:  0.9800\n",
      "Hold-out C Precision: 0.9800\n",
      "Hold-out C Recall:    0.9800\n",
      "Hold-out C F1 Score:   0.9800\n",
      "HOLD OUT A DATA\n",
      "True_Value\n",
      "0    99\n",
      "1     1\n",
      "Name: count, dtype: int64\n",
      "Predictions\n",
      "0    96\n",
      "1     4\n",
      "Name: count, dtype: int64\n",
      "HOLD OUT B DATA\n",
      "True_Value\n",
      "0    99\n",
      "1     1\n",
      "Name: count, dtype: int64\n",
      "Predictions\n",
      "0    98\n",
      "1     2\n",
      "Name: count, dtype: int64\n",
      "HOLD OUT C DATA\n",
      "True_Value\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "Predictions\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "Evaluation DONE\n"
     ]
    }
   ],
   "source": [
    "# Load the full FraudPipeline object\n",
    "fp_loaded = joblib.load(\"artifacts/fraud_pipeline.pkl\")\n",
    "\n",
    "# fp_loaded.best_threshold = 0.9\n",
    "\n",
    "# Use predict with stored best_threshold\n",
    "preds_A = fp_loaded.predict_pipeline(X_holdout_A, use_optimal_threshold=True)\n",
    "preds_B = fp_loaded.predict_pipeline(X_holdout_B, use_optimal_threshold=True)\n",
    "preds_C = fp_loaded.predict_pipeline(X_holdout_C, use_optimal_threshold=True)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(y_holdout_A, preds_A, dataset_name=\"Hold-out A\")\n",
    "evaluate_model(y_holdout_B, preds_B, dataset_name=\"Hold-out B\")\n",
    "evaluate_model(y_holdout_C, preds_C, dataset_name=\"Hold-out C\")\n",
    "\n",
    "print('HOLD OUT A DATA')\n",
    "print(pd.DataFrame({'Predictions': preds_A, 'True_Value': y_holdout_A})['True_Value'].value_counts())\n",
    "print(pd.DataFrame({'Predictions': preds_A, 'True_Value': y_holdout_A})['Predictions'].value_counts())\n",
    "print('HOLD OUT B DATA')\n",
    "print(pd.DataFrame({'Predictions': preds_B, 'True_Value': y_holdout_B})['True_Value'].value_counts())\n",
    "print(pd.DataFrame({'Predictions': preds_B, 'True_Value': y_holdout_B})['Predictions'].value_counts())\n",
    "print('HOLD OUT C DATA')\n",
    "print(pd.DataFrame({'Predictions': preds_C, 'True_Value': y_holdout_C})['True_Value'].value_counts())\n",
    "print(pd.DataFrame({'Predictions': preds_C, 'True_Value': y_holdout_C})['Predictions'].value_counts())\n",
    "\n",
    "print('Evaluation DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bff49d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined data to combined_holdout.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine X and y for each holdout\n",
    "df_A = X_holdout_A.copy()\n",
    "df_A[\"target\"] = y_holdout_A\n",
    "\n",
    "df_B = X_holdout_B.copy()\n",
    "df_B[\"target\"] = y_holdout_B\n",
    "\n",
    "df_C = X_holdout_C.copy()\n",
    "df_C[\"target\"] = y_holdout_C\n",
    "\n",
    "# Add dataset label for clarity\n",
    "df_A[\"dataset\"] = \"A\"\n",
    "df_B[\"dataset\"] = \"B\"\n",
    "df_C[\"dataset\"] = \"C\"\n",
    "\n",
    "# Concatenate all\n",
    "combined_df = pd.concat([df_A, df_B, df_C], axis=0)\n",
    "\n",
    "# Save to CSV\n",
    "combined_df.to_csv(r\"C:\\Users\\Asus\\Downloads\\Fraud_MLOps_Project\\Data\\combined_holdout.csv\", index=False)\n",
    "print(\"Saved combined data to combined_holdout.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b012ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'FraudDetectionPipeline' already exists. Creating a new version of this model...\n",
      "2025/08/02 00:27:45 WARNING mlflow.tracking._model_registry.fluent: Run with id 15524d0ab8f94e6b9e266d6f7e36ea15 has no artifacts at artifact path 'fraud_pipeline', registering model based on models:/m-f8ae82f65eaf4a12b5d02dce9939bf52 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered as 'FraudDetectionPipeline' with version 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'FraudDetectionPipeline'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1754074665635, current_stage='None', deployment_job_state=None, description=None, last_updated_timestamp=1754074665635, metrics=[<Metric: dataset_digest=None, dataset_name=None, key='test_accuracy', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637577, value=0.9217052103650042>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='test_f1', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637599, value=0.19714285714285715>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='test_precision', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637584, value=0.10935023771790808>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='test_pr_auc', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637612, value=0.4475153883934706>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='test_recall', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637591, value=1.0>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='train_accuracy', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637547, value=0.9616845436961491>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='train_f1', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637568, value=0.9630320818417794>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='train_precision', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637554, value=0.9303133604300511>,\n",
       " <Metric: dataset_digest=None, dataset_name=None, key='train_recall', model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', run_id='15524d0ab8f94e6b9e266d6f7e36ea15', step=0, timestamp=1754074637561, value=0.9981360998769122>], model_id='m-f8ae82f65eaf4a12b5d02dce9939bf52', name='FraudDetectionPipeline', params={'categorical_features': \"['Category', 'paymentMethod', 'isWeekend']\",\n",
       " 'class_distribution': '{\"0\": 0.990414623272403, \"1\": 0.009585376727596968}',\n",
       " 'model': 'LogisticRegression',\n",
       " 'optimal_threshold': '0.8367815357592582',\n",
       " 'resample_method': 'smote',\n",
       " 'skewed_features': \"['numItems', 'localTime', 'paymentMethodAgeDays']\",\n",
       " 'steps_to_apply': \"['preprocessing', 'model_training', 'smote', 'impute', \"\n",
       "                   \"'interaction', 'time_feature', 'encoding', 'binning', \"\n",
       "                   \"'log_transform', 'feature_engineering', 'ratio']\",\n",
       " 'symmetric_features': \"['accountAgeDays']\",\n",
       " 'test_size': '0.2'}, run_id='15524d0ab8f94e6b9e266d6f7e36ea15', run_link=None, source='models:/m-f8ae82f65eaf4a12b5d02dce9939bf52', status='READY', status_message=None, tags={}, user_id=None, version=7>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "# def register_last_model(run_id = None, model_name=\"FraudDetectionModel\"):\n",
    "#     # Get last active run\n",
    "#     run = mlflow.active_run()\n",
    "#     if run is None:\n",
    "#         # If not active, get last finished run from experiment\n",
    "#         client = MlflowClient()\n",
    "#         experiment = mlflow.get_experiment_by_name(\"FraudDetection\")\n",
    "#         runs = client.search_runs(\n",
    "#             experiment_ids=[experiment.experiment_id],\n",
    "#             order_by=[\"start_time DESC\"],\n",
    "#             max_results=1\n",
    "#         )\n",
    "#         run_id = run_id\n",
    "#     else:\n",
    "#         run_id = run.info.run_id\n",
    "\n",
    "#     # Model URI where sklearn model was logged\n",
    "#     model_uri = f\"runs:/{run_id}/fraud_pipeline\"\n",
    "\n",
    "#     # Register model\n",
    "#     registered_model = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "#     print(f\"Model registered as '{model_name}' with version {registered_model.version}\")\n",
    "#     return registered_model\n",
    "\n",
    "# # Example usage (after training):\n",
    "# register_last_model(run_id='15524d0ab8f94e6b9e266d6f7e36ea15', model_name=\"FraudDetectionPipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d699fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: file:///c:/Users/Asus/Downloads/Fraud_MLOps_Project/Notebooks/mlruns/369953768913727304/models/m-f8ae82f65eaf4a12b5d02dce9939bf52/artifacts\n",
       "  flavor: mlflow.pyfunc.model\n",
       "  run_id: 15524d0ab8f94e6b9e266d6f7e36ea15"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Set model version alias\n",
    "model_name = \"FraudDetectionPipeline\"\n",
    "model_version_alias = \"champion\"\n",
    "client.set_registered_model_alias(\n",
    "    model_name, model_version_alias, \"7\"\n",
    ")  # Duplicate of step in UI\n",
    "\n",
    "# Get information about the model\n",
    "model_info = client.get_model_version_by_alias(model_name, model_version_alias)\n",
    "model_tags = model_info.tags\n",
    "print(model_tags)\n",
    "\n",
    "# Get the model version using a model URI\n",
    "model_uri = f\"models:/{model_name}@{model_version_alias}\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1c8e3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions sample:\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      "target\n",
      "0    248\n",
      "1     52\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    244\n",
       "1     56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Separate features\n",
    "X_combined = combined_df.drop(['target', 'dataset'], axis=1)\n",
    "y_combined = combined_df['target']\n",
    "\n",
    "# Get predictions\n",
    "preds = model.predict(X_combined)\n",
    "\n",
    "# Evaluate or inspect predictions\n",
    "print(\"Predictions sample:\\n\", preds[:10])\n",
    "\n",
    "print(combined_df['target'].value_counts())\n",
    "pd.DataFrame(preds).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ecb1d",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8aa441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns BEFORE Feature Engineering:\n",
      "['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend']\n",
      "\n",
      "Columns AFTER Feature Engineering:\n",
      "['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend', 'Category_Payment', 'payment_account_ratio', 'account_age_bin', 'time_of_day']\n",
      "\n",
      "Newly added columns: {'account_age_bin', 'time_of_day', 'payment_account_ratio', 'Category_Payment'}\n",
      "\n",
      "Sample transformed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>Category_Payment</th>\n",
       "      <th>payment_account_ratio</th>\n",
       "      <th>account_age_bin</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_paypal</td>\n",
       "      <td>0.940162</td>\n",
       "      <td>new</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>electronics_storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>food_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>electronics_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend         Category_Payment  payment_account_ratio  \\\n",
       "0     shopping        0.0          shopping_paypal               0.940162   \n",
       "1  electronics        0.0  electronics_storecredit               0.000000   \n",
       "2         food        1.0          food_creditcard               0.000000   \n",
       "3  electronics        1.0   electronics_creditcard               0.000000   \n",
       "4     shopping        0.0      shopping_creditcard               0.000000   \n",
       "\n",
       "  account_age_bin time_of_day  \n",
       "0             new       night  \n",
       "1          medium       night  \n",
       "2             old       night  \n",
       "3          medium       night  \n",
       "4             old       night  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Split your dataset ---\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Instantiate FeatureEngineering\n",
    "fe = FeatureEngineering(steps_to_apply=['feature_engineering', 'interaction', 'ratio', 'binning', 'time_feature'])\n",
    "\n",
    "# BEFORE: Inspect original columns\n",
    "print(\"Columns BEFORE Feature Engineering:\")\n",
    "print(list(X.columns))\n",
    "\n",
    "# Apply Feature Engineering\n",
    "X_transformed = fe.fit_transform(X)\n",
    "\n",
    "# AFTER: Inspect new columns\n",
    "print(\"\\nColumns AFTER Feature Engineering:\")\n",
    "print(list(X_transformed.columns))\n",
    "\n",
    "# Compare column difference\n",
    "added_columns = set(X_transformed.columns) - set(X.columns)\n",
    "print(\"\\nNewly added columns:\", added_columns)\n",
    "\n",
    "# Show head of transformed data\n",
    "print(\"\\nSample transformed data:\")\n",
    "display(X_transformed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98315ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Columns: ['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend  \n",
       "0     shopping        0.0  \n",
       "1  electronics        0.0  \n",
       "2         food        1.0  \n",
       "3  electronics        1.0  \n",
       "4     shopping        0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Shape: (39221, 9)\n",
      "Transformed Columns (after encoding, scaling, log):\n",
      "['Category_food', 'Category_shopping', 'paymentMethod_paypal', 'paymentMethod_storecredit', 'isWeekend_1.0', 'numItems', 'localTime', 'paymentMethodAgeDays', 'accountAgeDays']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_food</th>\n",
       "      <th>Category_shopping</th>\n",
       "      <th>paymentMethod_paypal</th>\n",
       "      <th>paymentMethod_storecredit</th>\n",
       "      <th>isWeekend_1.0</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>accountAgeDays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.362181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.422211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.251126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_food  Category_shopping  paymentMethod_paypal  \\\n",
       "0            0.0                1.0                   1.0   \n",
       "1            0.0                0.0                   0.0   \n",
       "2            1.0                0.0                   0.0   \n",
       "3            0.0                0.0                   0.0   \n",
       "4            0.0                1.0                   0.0   \n",
       "\n",
       "   paymentMethod_storecredit  isWeekend_1.0  numItems  localTime  \\\n",
       "0                        0.0            0.0 -0.189142   0.028772   \n",
       "1                        1.0            0.0 -0.189142   0.021742   \n",
       "2                        0.0            1.0 -0.189142   0.421745   \n",
       "3                        0.0            1.0 -0.189142   0.345213   \n",
       "4                        0.0            0.0 -0.189142   0.682328   \n",
       "\n",
       "   paymentMethodAgeDays  accountAgeDays  \n",
       "0              0.557839        0.014007  \n",
       "1             -0.775564        0.362181  \n",
       "2             -0.775564        0.422211  \n",
       "3             -0.775564        0.251126  \n",
       "4             -0.775564        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_feature_names_from_column_transformer(column_transformer):\n",
    "    output_features = []\n",
    "    for name, pipe, features in column_transformer.transformers_:\n",
    "        if name != 'remainder':\n",
    "            if hasattr(pipe, 'named_steps'):\n",
    "                last_step = list(pipe.named_steps.values())[-1]\n",
    "                if hasattr(last_step, 'get_feature_names_out'):\n",
    "                    feature_names = last_step.get_feature_names_out(features)\n",
    "                else:\n",
    "                    feature_names = features\n",
    "            else:\n",
    "                feature_names = features\n",
    "            output_features.extend(feature_names)\n",
    "        else:\n",
    "            output_features.extend(features)  # passthrough features\n",
    "    return output_features\n",
    "\n",
    "# Assume you have X (original features) and Preprocessing object\n",
    "pre = Preprocessing(\n",
    "    categorical_features=['Category', 'paymentMethod', 'isWeekend'],\n",
    "    skewed_features=['numItems', 'localTime', 'paymentMethodAgeDays'],\n",
    "    symmetric_features=['accountAgeDays'],\n",
    "    steps_to_apply=['preprocessing']  # full preprocessing\n",
    ")\n",
    "\n",
    "# BEFORE: original data\n",
    "print(\"Original Columns:\", X.columns.tolist())\n",
    "display(X.head())\n",
    "\n",
    "# Fit + transform\n",
    "X_transformed = pre.fit_transform(X)\n",
    "\n",
    "# Get transformed column names\n",
    "transformed_cols = get_feature_names_from_column_transformer(pre.preprocessor)\n",
    "\n",
    "# AFTER: transformed data\n",
    "print(\"\\nTransformed Shape:\", X_transformed.shape)\n",
    "print(\"Transformed Columns (after encoding, scaling, log):\")\n",
    "print(transformed_cols)\n",
    "\n",
    "# Convert transformed array to DataFrame for easy inspection\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=transformed_cols)\n",
    "\n",
    "# Show first few rows\n",
    "display(X_transformed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04aa1313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed columns:\n",
      "['Category_food', 'Category_shopping', 'paymentMethod_paypal', 'paymentMethod_storecredit', 'isWeekend_1.0', 'numItems', 'localTime', 'paymentMethodAgeDays', 'accountAgeDays']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_food</th>\n",
       "      <th>Category_shopping</th>\n",
       "      <th>paymentMethod_paypal</th>\n",
       "      <th>paymentMethod_storecredit</th>\n",
       "      <th>isWeekend_1.0</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>accountAgeDays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.362181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.422211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.251126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_food  Category_shopping  paymentMethod_paypal  \\\n",
       "0            0.0                1.0                   1.0   \n",
       "1            0.0                0.0                   0.0   \n",
       "2            1.0                0.0                   0.0   \n",
       "3            0.0                0.0                   0.0   \n",
       "4            0.0                1.0                   0.0   \n",
       "\n",
       "   paymentMethod_storecredit  isWeekend_1.0  numItems  localTime  \\\n",
       "0                        0.0            0.0 -0.189142   0.028772   \n",
       "1                        1.0            0.0 -0.189142   0.021742   \n",
       "2                        0.0            1.0 -0.189142   0.421745   \n",
       "3                        0.0            1.0 -0.189142   0.345213   \n",
       "4                        0.0            0.0 -0.189142   0.682328   \n",
       "\n",
       "   paymentMethodAgeDays  accountAgeDays  \n",
       "0              0.557839        0.014007  \n",
       "1             -0.775564        0.362181  \n",
       "2             -0.775564        0.422211  \n",
       "3             -0.775564        0.251126  \n",
       "4             -0.775564        1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_preprocessed_dataframe(preprocessor_obj, X):\n",
    "    \"\"\"\n",
    "    Returns preprocessed dataframe with column names after transformation.\n",
    "    \"\"\"\n",
    "    # Fit and transform\n",
    "    X_transformed = preprocessor_obj.fit_transform(X)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = get_feature_names_from_column_transformer(preprocessor_obj.preprocessor)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    preprocessed_df = pd.DataFrame(X_transformed, columns=feature_names, index=X.index)\n",
    "    \n",
    "    return preprocessed_df\n",
    "\n",
    "\n",
    "# ---------- Usage ----------\n",
    "# Initialize Preprocessing object\n",
    "pre = Preprocessing(\n",
    "    categorical_features=['Category', 'paymentMethod', 'isWeekend'],\n",
    "    skewed_features=['numItems', 'localTime', 'paymentMethodAgeDays'],\n",
    "    symmetric_features=['accountAgeDays'],\n",
    "    steps_to_apply=['preprocessing']  # includes impute, encoding, scaling, log\n",
    ")\n",
    "\n",
    "# Get preprocessed DataFrame\n",
    "preprocessed_df = get_preprocessed_dataframe(pre, X)\n",
    "\n",
    "# Show\n",
    "print(\"Preprocessed columns:\")\n",
    "print(preprocessed_df.columns.tolist())\n",
    "display(preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0feeb7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineered Columns:\n",
      "['accountAgeDays', 'numItems', 'localTime', 'paymentMethod', 'paymentMethodAgeDays', 'Category', 'isWeekend', 'Category_Payment', 'payment_account_ratio', 'account_age_bin', 'time_of_day']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethod</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>Category</th>\n",
       "      <th>isWeekend</th>\n",
       "      <th>Category_Payment</th>\n",
       "      <th>payment_account_ratio</th>\n",
       "      <th>account_age_bin</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.204861</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_paypal</td>\n",
       "      <td>0.940162</td>\n",
       "      <td>new</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0.0</td>\n",
       "      <td>electronics_storecredit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.921318</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>food</td>\n",
       "      <td>1.0</td>\n",
       "      <td>food_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.886641</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>electronics_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>medium</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.040929</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>shopping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shopping_creditcard</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>old</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAgeDays  numItems  localTime paymentMethod  paymentMethodAgeDays  \\\n",
       "0              29         1   4.745402        paypal             28.204861   \n",
       "1             725         1   4.742303   storecredit              0.000000   \n",
       "2             845         1   4.921318    creditcard              0.000000   \n",
       "3             503         1   4.886641    creditcard              0.000000   \n",
       "4            2000         1   5.040929    creditcard              0.000000   \n",
       "\n",
       "      Category  isWeekend         Category_Payment  payment_account_ratio  \\\n",
       "0     shopping        0.0          shopping_paypal               0.940162   \n",
       "1  electronics        0.0  electronics_storecredit               0.000000   \n",
       "2         food        1.0          food_creditcard               0.000000   \n",
       "3  electronics        1.0   electronics_creditcard               0.000000   \n",
       "4     shopping        0.0      shopping_creditcard               0.000000   \n",
       "\n",
       "  account_age_bin time_of_day  \n",
       "0             new       night  \n",
       "1          medium       night  \n",
       "2             old       night  \n",
       "3          medium       night  \n",
       "4             old       night  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Columns:\n",
      "['Category_food', 'Category_shopping', 'paymentMethod_paypal', 'paymentMethod_storecredit', 'isWeekend_1.0', 'Category_Payment_electronics_paypal', 'Category_Payment_electronics_storecredit', 'Category_Payment_food_creditcard', 'Category_Payment_food_paypal', 'Category_Payment_food_storecredit', 'Category_Payment_shopping_creditcard', 'Category_Payment_shopping_paypal', 'Category_Payment_shopping_storecredit', 'account_age_bin_new', 'account_age_bin_old', 'time_of_day_evening', 'time_of_day_night', 'numItems', 'localTime', 'paymentMethodAgeDays', 'accountAgeDays', 'payment_account_ratio']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category_food</th>\n",
       "      <th>Category_shopping</th>\n",
       "      <th>paymentMethod_paypal</th>\n",
       "      <th>paymentMethod_storecredit</th>\n",
       "      <th>isWeekend_1.0</th>\n",
       "      <th>Category_Payment_electronics_paypal</th>\n",
       "      <th>Category_Payment_electronics_storecredit</th>\n",
       "      <th>Category_Payment_food_creditcard</th>\n",
       "      <th>Category_Payment_food_paypal</th>\n",
       "      <th>Category_Payment_food_storecredit</th>\n",
       "      <th>...</th>\n",
       "      <th>Category_Payment_shopping_storecredit</th>\n",
       "      <th>account_age_bin_new</th>\n",
       "      <th>account_age_bin_old</th>\n",
       "      <th>time_of_day_evening</th>\n",
       "      <th>time_of_day_night</th>\n",
       "      <th>numItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>paymentMethodAgeDays</th>\n",
       "      <th>accountAgeDays</th>\n",
       "      <th>payment_account_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.028772</td>\n",
       "      <td>0.557839</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.940649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.362181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.421745</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.422211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.345213</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>0.251126</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.189142</td>\n",
       "      <td>0.682328</td>\n",
       "      <td>-0.775564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category_food  Category_shopping  paymentMethod_paypal  \\\n",
       "0            0.0                1.0                   1.0   \n",
       "1            0.0                0.0                   0.0   \n",
       "2            1.0                0.0                   0.0   \n",
       "3            0.0                0.0                   0.0   \n",
       "4            0.0                1.0                   0.0   \n",
       "\n",
       "   paymentMethod_storecredit  isWeekend_1.0  \\\n",
       "0                        0.0            0.0   \n",
       "1                        1.0            0.0   \n",
       "2                        0.0            1.0   \n",
       "3                        0.0            1.0   \n",
       "4                        0.0            0.0   \n",
       "\n",
       "   Category_Payment_electronics_paypal  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   Category_Payment_electronics_storecredit  Category_Payment_food_creditcard  \\\n",
       "0                                       0.0                               0.0   \n",
       "1                                       1.0                               0.0   \n",
       "2                                       0.0                               1.0   \n",
       "3                                       0.0                               0.0   \n",
       "4                                       0.0                               0.0   \n",
       "\n",
       "   Category_Payment_food_paypal  Category_Payment_food_storecredit  ...  \\\n",
       "0                           0.0                                0.0  ...   \n",
       "1                           0.0                                0.0  ...   \n",
       "2                           0.0                                0.0  ...   \n",
       "3                           0.0                                0.0  ...   \n",
       "4                           0.0                                0.0  ...   \n",
       "\n",
       "   Category_Payment_shopping_storecredit  account_age_bin_new  \\\n",
       "0                                    0.0                  1.0   \n",
       "1                                    0.0                  0.0   \n",
       "2                                    0.0                  0.0   \n",
       "3                                    0.0                  0.0   \n",
       "4                                    0.0                  0.0   \n",
       "\n",
       "   account_age_bin_old  time_of_day_evening  time_of_day_night  numItems  \\\n",
       "0                  0.0                  0.0                1.0 -0.189142   \n",
       "1                  0.0                  0.0                1.0 -0.189142   \n",
       "2                  1.0                  0.0                1.0 -0.189142   \n",
       "3                  0.0                  0.0                1.0 -0.189142   \n",
       "4                  1.0                  0.0                1.0 -0.189142   \n",
       "\n",
       "   localTime  paymentMethodAgeDays  accountAgeDays  payment_account_ratio  \n",
       "0   0.028772              0.557839        0.014007               0.940649  \n",
       "1   0.021742             -0.775564        0.362181               0.000000  \n",
       "2   0.421745             -0.775564        0.422211               0.000000  \n",
       "3   0.345213             -0.775564        0.251126               0.000000  \n",
       "4   0.682328             -0.775564        1.000000               0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize FeatureEngineering with chosen steps\n",
    "fe = FeatureEngineering(\n",
    "    steps_to_apply=['feature_engineering', 'interaction', 'ratio', 'binning', 'time_feature']\n",
    ")\n",
    "\n",
    "# Apply feature engineering\n",
    "X_fe = fe.fit_transform(X)\n",
    "\n",
    "print(\"Feature Engineered Columns:\")\n",
    "print(X_fe.columns.tolist())\n",
    "display(X_fe.head())\n",
    "\n",
    "# Initialize Preprocessing with chosen steps\n",
    "pre = Preprocessing(\n",
    "    categorical_features=['Category', 'paymentMethod', 'isWeekend', 'Category_Payment', 'account_age_bin', 'time_of_day'],\n",
    "    skewed_features=['numItems', 'localTime', 'paymentMethodAgeDays'],\n",
    "    symmetric_features=['accountAgeDays', 'payment_account_ratio'],\n",
    "    steps_to_apply=['preprocessing']  # includes impute, encoding, log, scaling\n",
    ")\n",
    "\n",
    "# Fit & transform feature engineered data\n",
    "X_preprocessed = pre.fit_transform(X_fe)\n",
    "\n",
    "# Extract transformed feature names\n",
    "feature_names = get_feature_names_from_column_transformer(pre.preprocessor)\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=feature_names, index=X_fe.index)\n",
    "\n",
    "print(\"\\nPreprocessed Columns:\")\n",
    "print(X_preprocessed_df.columns.tolist())\n",
    "display(X_preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad61fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
